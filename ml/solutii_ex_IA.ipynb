{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fbde7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from urllib import request\n",
    "import gzip\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load():\n",
    "    with open(\"data.pkl\",'rb') as f:\n",
    "        mnist = pickle.load(f)\n",
    "    return mnist[\"training_images\"], mnist[\"training_labels\"], mnist[\"test_images\"], mnist[\"test_labels\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10ae1356",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_images, train_labels, test_images, test_labels = load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "830b34de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(-1, 28, 28)#[:5000]\n",
    "test_images = test_images.reshape(-1, 28, 28)#[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faa946d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels#[:5000]\n",
    "test_labels = test_labels#[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "518816aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x10F236970>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "Image.fromarray(train_images[0].astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74693828",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:57<00:00, 87.34it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Ex1\n",
    "def binary2decimal(binary):\n",
    "    return sum(val*(2**idx) for idx, val in enumerate(reversed(binary)))\n",
    "\n",
    "def f_ex1(image, d=3):\n",
    "    h,w = image.shape\n",
    "    size_left_right = (d-1)//2\n",
    "    size_up_down = (d-1)//2\n",
    "    padded_image = np.pad(image, ((size_up_down, size_up_down), (size_left_right, size_left_right)),\n",
    "                          constant_values=-1)\n",
    "    results = []\n",
    "    for i in range(size_up_down, h):\n",
    "        for j in range(size_left_right, w):\n",
    "            output_representation = np.zeros((d*d)-1)\n",
    "            patch = padded_image[i-size_left_right:i+size_left_right+1,\n",
    "                          j-size_up_down:j+size_up_down+1]\n",
    "            value =padded_image[i][j]\n",
    "            comparison = (patch>value)*1\n",
    "            result = comparison.reshape(-1)\n",
    "\n",
    "            output_representation[:len(output_representation)//2] = result[:len(output_representation)//2]\n",
    "            output_representation[len(output_representation)//2:] = result[len(output_representation)//2 + 1:]\n",
    "            results.append(output_representation)\n",
    " \n",
    "    histogram = np.zeros((2**(d*d-1)))\n",
    "    for result in results:\n",
    "        position = binary2decimal(result)\n",
    "        histogram[int(position)]+=1\n",
    "    return histogram\n",
    "\n",
    "def process_data(images):\n",
    "    results = []\n",
    "    for image in tqdm(images):\n",
    "        hist = f_ex1(image)\n",
    "        results.append(hist)\n",
    "    return np.array(results)\n",
    "\n",
    "train_hist = process_data(train_images)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "430bc4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:22<00:00, 87.92it/s]\n"
     ]
    }
   ],
   "source": [
    "test_hist = process_data(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b12a28a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "clf = SVC()\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_hist)\n",
    "train_hist_scaled = scaler.transform(train_hist)\n",
    "test_hist_scaled = scaler.transform(test_hist)\n",
    "clf.fit(train_hist_scaled, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aea0ac90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7435"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_hist_scaled, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd5a46b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hist[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a833ba9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 26000.51it/s]\n"
     ]
    }
   ],
   "source": [
    "### Ex2\n",
    "import cv2\n",
    "def compute_gradient_magnitude(image):\n",
    "    sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    grad_mag = np.sqrt(np.square(sobelx) + np.square(sobely))\n",
    "    return grad_mag\n",
    "def process_images(images):\n",
    "    results = []\n",
    "    for image in tqdm(images):\n",
    "        results.append(compute_gradient_magnitude(image))\n",
    "    return np.array(results)\n",
    "\n",
    "train_grad_mag = process_images(train_images)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3f4b4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 34553.58it/s]\n"
     ]
    }
   ],
   "source": [
    "test_grad_mag = process_images(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3f4150e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:01<00:00, 3964.99it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 3535.51it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_top_k_regions(grad_mag, original_image, k=30, d=4):\n",
    "    patches_mag = grad_mag.reshape(-1, d, d)\n",
    "    original_image = original_image.reshape(-1, d, d)\n",
    "    patches_mag = np.mean(patches_mag, axis=(1, 2))\n",
    "    sorted_indices = np.argsort(patches_mag)\n",
    "    output = []\n",
    "    for i in range(original_image.shape[0]):\n",
    "        if i not in sorted_indices[-k:]:\n",
    "            continue\n",
    "        output.append(original_image[i])\n",
    "    return np.array(output).reshape(-1)\n",
    "\n",
    "def transform_images(images, grad_mags):\n",
    "    results = []\n",
    "    for i, image in enumerate(tqdm(images)):\n",
    "        results.append(get_top_k_regions(grad_mags[i], image))\n",
    "    return np.array(results)\n",
    "\n",
    "ex2_train_data = transform_images(train_images, train_grad_mag)\n",
    "ex2_test_data = transform_images(test_images, test_grad_mag)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0df963c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "clf = SVC(C=10)\n",
    "\n",
    "clf.fit(ex2_train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86de0217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8565"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(ex2_test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d879c13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 5000/5000 [00:00<00:00, 31488.72it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 2000/2000 [00:00<00:00, 32797.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# Ex3\n",
    "def compute_gradient_direction(image):\n",
    "    sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    grad_direction = np.arctan2(sobely, sobelx)\n",
    "    return grad_direction\n",
    "\n",
    "def process_images(images):\n",
    "    results = []\n",
    "    for image in tqdm(images):\n",
    "        results.append(compute_gradient_direction(image))\n",
    "    return np.array(results)\n",
    "train_grad_direction = process_images(train_images)\n",
    "test_grad_direction = process_images(test_images)\n",
    "    \n",
    "def non_max_suppression_gradient(img, direction):\n",
    "    h, w = img.shape\n",
    "    output = np.zeros((h,w), dtype=np.int32)\n",
    "    angle = direction * 180. / np.pi\n",
    "    angle[angle < 0] += 180\n",
    "\n",
    "    for i in range(1,h-1):\n",
    "        for j in range(1,w-1):\n",
    "            neighbour1 = 255\n",
    "            neighbour2 = 255\n",
    "                \n",
    "            if (0 <= angle[i,j] < 22.5) or (157.5 <= angle[i,j] <= 180):\n",
    "                neighbour1 = img[i, j+1]\n",
    "                neighbour2 = img[i, j-1]\n",
    "  \n",
    "            elif (22.5 <= angle[i,j] < 67.5):\n",
    "                neighbour1 = img[i+1, j-1]\n",
    "                neighbour2 = img[i-1, j+1]\n",
    "\n",
    "            elif (67.5 <= angle[i,j] < 112.5):\n",
    "                neighbour1 = img[i+1, j]\n",
    "                neighbour2 = img[i-1, j]\n",
    "\n",
    "            elif (112.5 <= angle[i,j] < 157.5):\n",
    "                neighbour1 = img[i-1, j-1]\n",
    "                neighbour2 = img[i+1, j+1]\n",
    "\n",
    "            if (img[i,j] >= neighbour1) and (img[i,j] >= neighbour2):\n",
    "                output[i,j] = img[i,j]\n",
    "            else:\n",
    "                output[i,j] = 0\n",
    "    \n",
    "    return output\n",
    "\n",
    "def process_image(mags, directions):\n",
    "    results = []\n",
    "    for i, mag in enumerate(mags):\n",
    "        results.append(non_max_suppression_gradient(mag, directions[i]))\n",
    "        \n",
    "    return np.array(results)\n",
    "\n",
    "new_train_mags = process_image(train_grad_mag, train_grad_direction)\n",
    "new_test_mags = process_image(test_grad_mag, test_grad_direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f11e917a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "clf = SVC(C=10)\n",
    "\n",
    "clf.fit(new_train_mags.reshape(-1,784), train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06aa1f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8505"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(new_test_mags.reshape(-1,784), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e314dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9 8 1 4 3 0 3 6 7 4]\n",
      " [8 3 2 4 4 8 7 8 1 0]\n",
      " [4 5 5 0 8 5 0 7 7 8]\n",
      " [5 7 2 1 6 7 4 5 7 9]\n",
      " [2 1 0 9 6 9 1 0 1 5]\n",
      " [5 9 8 4 5 0 9 9 4 9]\n",
      " [6 4 0 3 8 7 5 9 7 3]\n",
      " [4 6 2 5 4 6 6 0 8 3]\n",
      " [3 1 2 8 3 2 1 1 2 5]\n",
      " [5 5 9 8 4 6 2 2 9 2]]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.randint(low=0, high=10, size=(10,10))\n",
    "print(a)\n",
    "print(a[-1:3, 0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4476a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "526ecc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:04<00:00, 1026.43it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:01<00:00, 1086.40it/s]\n"
     ]
    }
   ],
   "source": [
    "## Ex 4\n",
    "def binarize_image(image, d=4):\n",
    "    patches = image.reshape(-1, d, d)\n",
    "    outputs = []\n",
    "    for patch in patches:\n",
    "        if d%2==0:\n",
    "            output_representation = np.zeros((d*d))\n",
    "            value = np.mean(patch[d//2-1: d//2+1,d//2-1: d//2+1])\n",
    "        else:\n",
    "            output_representation = np.zeros((d*d)-1)\n",
    "            value = patch[d//2, d//2]\n",
    "        comparison = (patch>=value)*1\n",
    "        result = comparison.reshape(-1)\n",
    "        if d%2==0:\n",
    "            output_representation= result\n",
    "        else:\n",
    "            output_representation[:len(output_representation)//2] = result[:len(output_representation)//2]\n",
    "            output_representation[len(output_representation)//2:] = result[len(output_representation)//2 + 1:]\n",
    "        outputs.append(output_representation)\n",
    "    return np.concatenate(outputs)\n",
    "def process_data(images):\n",
    "    results = []\n",
    "    for image in tqdm(images):\n",
    "        results.append(binarize_image(image))\n",
    "    return np.array(results)\n",
    "train_binary_data = process_data(train_images)\n",
    "test_binary_data = process_data(test_images)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77eacd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8625"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=7)\n",
    "neigh.fit(train_binary_data, train_labels)\n",
    "neigh.score(test_binary_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78abc26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [05:16<00:00, 15.79it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [04:19<00:00, 19.27it/s]\n"
     ]
    }
   ],
   "source": [
    "## Ex5\n",
    "def intersection_kernel(hist1, hist2):\n",
    "    hist1 = np.expand_dims(hist1, axis=0)\n",
    "    hist2 = np.expand_dims(hist2, axis=0)\n",
    "    concatenation = np.concatenate((hist1,hist2),axis=0)\n",
    "    minimum = np.min(concatenation,axis=0)\n",
    "    return np.sum(minimum)\n",
    "\n",
    "def compute_kernel_matrix(histograms1, histograms2, train=True):\n",
    "    kernel_matrix = np.zeros((len(histograms1), len(histograms2)))\n",
    "    if train:\n",
    "        for i in tqdm(range(len(histograms1))):\n",
    "            for j in range(i, len(histograms2)):\n",
    "                kernel_matrix[i][j] = intersection_kernel(histograms1[i], histograms2[j])\n",
    "                kernel_matrix[j][i] = kernel_matrix[i][j]\n",
    "    else:\n",
    "        for i in tqdm(range(len(histograms1))):\n",
    "            for j in range(len(histograms2)):\n",
    "                kernel_matrix[i][j] = intersection_kernel(histograms1[i], histograms2[j])\n",
    "    return kernel_matrix\n",
    "                   \n",
    "train_matrix = compute_kernel_matrix(train_hist_scaled, train_hist_scaled)\n",
    "test_matrix = compute_kernel_matrix(train_hist_scaled, test_hist_scaled, train=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "762c5477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.771"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(kernel='precomputed')\n",
    "\n",
    "clf.fit(train_matrix, train_labels)\n",
    "clf.score(test_matrix.T, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4e5070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
